---
title: "CS 422"
output: 
  html_notebook:
    toc: yes
    toc_float: yes
author: Ruchi Sharma
---

## Homework 2
## Part 2.1 Decision tree classification

```{r}
# Setting the seed to 1122
set.seed(1122)  
options("digits"=3)
#Reading the adult-test and adult-train data set
setwd("C:/Users/Ruchi Awasthi/Desktop/Masters/DM/Assignment 2")
adult_test.df = read.csv("adult-test.csv", header=TRUE, ",", comment.char = '#')
adult_train.df = read.csv("adult-train.csv", header=TRUE, ",", comment.char = '#')
```

# 2.1 (a.)
```{r}
#Checking which columns contains "?"
sum(adult_train.df$occupation == "?")
sum(adult_train.df$age == "?")
sum(adult_train.df$workclass == "?")
sum(adult_train.df$fnlwgt == "?")
sum(adult_train.df$education == "?")
sum(adult_train.df$education_num == "?")
sum(adult_train.df$marital_status == "?")
sum(adult_train.df$relationship == "?")
sum(adult_train.df$race == "?")
sum(adult_train.df$sex == "?")
sum(adult_train.df$capital_gain == "?")
sum(adult_train.df$capital_loss == "?")
sum(adult_train.df$hours_per_week == "?")
sum(adult_train.df$native_country== "?")
sum(adult_train.df$income== "?")

sum(adult_test.df$occupation == "?")
sum(adult_test.df$age == "?")
sum(adult_test.df$workclass == "?")
sum(adult_test.df$fnlwgt == "?")
sum(adult_test.df$education == "?")
sum(adult_test.df$education_num == "?")
sum(adult_test.df$marital_status == "?")
sum(adult_test.df$relationship == "?")
sum(adult_test.df$race == "?")
sum(adult_test.df$sex == "?")
sum(adult_test.df$capital_gain == "?")
sum(adult_test.df$capital_loss == "?")
sum(adult_test.df$hours_per_week == "?")
sum(adult_test.df$native_country== "?")
sum(adult_test.df$income== "?")

#Cleaning the training data set
#data frame with indices for unclean records
# Removing the adult train dataset- records with ? marks
adult_train.df <- adult_train.df[which(!adult_train.df$occupation == "?"),] 
adult_train.df <- adult_train.df[which(!adult_train.df$native_country == "?"),]
adult_train.df <- adult_train.df[which(!adult_train.df$workclass == "?"),]

#Cleaning the training dataset for unclean records
adult_test.df <- adult_test.df[which(!adult_test.df$occupation == "?"),] 
adult_test.df <- adult_test.df[which(!adult_test.df$native_country == "?"),]
adult_test.df <- adult_test.df[which(!adult_test.df$workclass == "?"),]
```

# 2.1 (b.)
```{r}
library(rpart)
library(rpart.plot)
tree <- rpart(income ~ .,data = adult_train.df,method = "class")
rpart.plot(tree, type = 4, extra = 104, fallen.leaves = TRUE, main="Plot for data on adult")
summary(tree)
```
#Part 2.1 (b.) 
#Part 2.1.b. (i) Answer
# Top three important predictors in the model are:  Relationship, Marital_Status and Capital Gain
#Part 2.1.b. (ii) Answer
# The first split is done on the basis of Relationship where left subtree consists of relationship status of {Not-in-family, Other-relative, Own-Child and Unmarried} and right subtree consists of relationship status of husband, wife
# Predicted class of the first node or root node is : income is <=50k.
# distribution of observations between the "<=50K" and ">50K" classes at first node is: 22653 (0.75 Percent) for income <=50k  and 7508 (0.25 percent) for income >50K


# 2.1 (c.)
```{r}
options("digits"=3)
library(caret)
install.packages('e1071', dependencies=TRUE)
# Predict the values of test data set
pred <- predict(tree, adult_test.df, type="class")
# Construct the confusion matrix
confusionMatrix(pred, adult_test.df[,15])
```

#Part 2.1.(c) Answer
#Part 2.1.c. (i) Answer
# Balanced Accuracy of the model per observation is : 0.726
# Part 2.1.c. (ii) Answer
# Balanced Error  rate as per confusion matrix is : 1-0.726 = 0.274
# Part 2.1.c. (iii) Answer
# Sensitivity of the model is : 0.948 and Specificity of the model is : 0.504


# Part 2.1.c. (iV) 

```{r}
library(pROC)
library(ROCR)
PredictionWithProb <- predict(tree, adult_test.df, type="prob")[,2]
pre<-prediction(PredictionWithProb, adult_test.df$income)
perf <- performance(pre, "tpr", "fpr")
plot(perf, colorize=T, lwd=3)
abline(0,1)
auc <- performance(pre, measure = "auc")
cat(paste("The area under curve (AUC) for this model is ", round(auc@y.values[[1]], 3)))
```
# Part 2.1.c. (iV) Answer Area Underr the curve is 0.843


#Part 2.1.(d) 
```{r}
library(rattle)
options("digits" =3)
printcp(tree)
plotcp(tree,minline = TRUE, lty = 3, col = 1)
```
# Part 2.1.(d) Observation
# By observation there are 4 splits in the tree. The root node error is 0.2. By observing complexity table we can see that complexity index(cp)  and the cross validation error(xerror) among the levels of the tree. If we go from top to bottom node, the complexity is getting reduced. At the bottom node the cp= 0.01 and xerror= 0.6 which is minimum. This shows the model fits the data set. With this model, pruning won't reduce the cp or xerror rate and hence is an optimal fit to the training data set.


#Part 2.1.e (i) 
```{r}
summary(adult_train.df$income)
```
# observations are in the class "<=50K": 22653
# observations are in the class ">50K": 7508

#Part 2.1.e (ii)
```{r}
subsetData <- subset(adult_train.df, adult_train.df$income == '>50K')
subsetData1 <- subset(adult_train.df, adult_train.df$income == '<=50K')
sampledLT50k <- sample(1:nrow(subsetData1),size = 7508)
sampledData <- subsetData1 [sampledLT50k,]
final.df <- rbind(sampledData,subsetData)
```

#Part 2.1.e (iii) 
```{r}
library(rpart)
library(rpart.plot)
model <- rpart(income ~ .,data = final.df, method = "class")
rpart.plot(model, type = 4, extra = 104, fallen.leaves = TRUE, main="Plot for sampled and merged data on adult")
summary(model)
predModel <- predict(model, adult_test.df, type="class")
# Construct the confusion matrix
confusionMatrix(predModel, adult_test.df[,15])
#ROC Curve
Prediction_new <- predict(model, adult_test.df, type="prob")[,2]
prediction_model<-prediction(Prediction_new, adult_test.df$income)
perf_model <- performance(prediction_model, "tpr", "fpr")
plot(perf_model, colorize=T, lwd=3)
abline(0,1)
#AUC value computation
auc <- performance(prediction_model, measure = "auc")
#rounding AUC 
cat(paste("The area under curve (AUC) for this model is ", round(auc@y.values[[1]], 3)))
```
#Part 2.1.e (iii) observations
#Part 2.1.e (iii) - i, ii, iii, iv Answers
# Balanced Accuracy of the Model is: 0.809
# Balanced error rate of the model is 1 - 0.809 = 0.191.
# The sensitivity is 0.782 and specificity is 0.835.
# The area under curve (AUC) for this model is  0.846

#Part 2.1.f
#After using the new model the balanced accuracy has increased from 0.726 to 0.809 leading to low balanced error. The negative class were relatively more in the new training data, leading to higher Specificity. This also gave the capability to the model to predict more negative classes which inturn increased error for the positive class, leading to low Sensitivity in the new model. The AUC for both models is relatively same, because due to increase in Specificity ,the false alarm rate increase leading to same error rate among the models.

### Part 2.2

#Part 2.2.a
```{r}
library(randomForest)
options("digits"=3)
set.seed(1122)
model_rm <- randomForest(income ~ .,data = adult_train.df,importance = T)
print(model_rm)
pred_rm <- predict(model_rm,adult_test.df,type = "class")
print("The prediction model summary is:")
summary(pred_rm)
confusionMatrix(pred_rm,adult_test.df[,15])
```
#Part 2.2.a Observations: 
#Part 2.2.a. -i 
#The Balanced Accuracy of the model is 0.784. 
#Part 2.2.a. -ii 
# Accuracy of the model is 0.858.
#Part 2.2.a. -iii
#The sensitivity of the model is 0.930 and specificity is 0.638.

#Part 2.2.a. -iV
```{r}
summary(adult_test.df$income)
```

#The distribution of the test dataset is: Class "<=50K" is 11360 and Class ">50K" is  3700.
#Part 2.2.a. -V 
#From the confusion matrix of training dataset, we can see that there are more records of positive class as comparision to negative class, which leads to a more predictions for positive class, leading to high Sensitivity and low Specificity value(due to high FP values).    

#Part 2.2.a- vi
```{r}
varImpPlot(model_rm)
print(model_rm)
```
#Part 2.2.a- vi Observation
# For MeanDecreaseAccuracy, The minimum important variable is : fnlwgt & Most important variable is: capital_gain.
#For MeanDecreaseGini: The most important variable is:  relationship & least important is : race  

#Part 2.2.a- vii
```{r}
print(model_rm)
```

#Part 2.2.a- vii Observations
# No. of variables tried at each split: 3

#Part 2.2.b
```{r}
mtry <-tuneRF(adult_train.df[,1:14],adult_train.df$income,ntreeTry = 500,stepFactor = 1.5,improve = 0.01,trace = TRUE,plot = TRUE) 
print(mtry)
```
#Part 2.2.b -i
# default value of mtry: 3

#Part 2.2.b -ii
# The optimal value of mtry from tuning RF is 2.
```{r}
optimal_rf <- randomForest(income ~ .,data = adult_train.df,importance = T,mtry= 2)
pred_rm <- predict(optimal_rf,adult_test.df,type = "class")
confusionMatrix(pred_rm, adult_test.df[,15])
```
#Part 2.2.b iii- 1
#Balanced Accuracy of the model is 0.784
#Part 2.2.b iii- 2
#Accuracy of the model is 0.861
#Part 2.2.b iii- 3
#Sensitivity of the model is : 0.935 and specificity of the model is : 0.633

#Part 2.2.b iii- 4
```{r}
varImpPlot(optimal_rf)
print(optimal_rf)
```
# For MeanDecreaseAccuracy most important variable is capital_gain and least important one is fnlwgt 
# For MeanDecreaseGini The most important variable is : capital_gain and least important is: race.

#Part 2.2.b iV
#In comparing both models, tuning the model has marginally improved the Accuracies of latter model and in the Mean Decrease Gini plot for variable importance, relationship variable has relatively similar gini index as compared to the last plot and but an increase in capital_gain plot. This is due to large decrease in Gini index Gain for capital_gain variable. There is least decrease in accuracy for native_country variable and least decrease gini for race as compared to the previous model.



### Part 2.3 Association Rules  
```{r}
#Loading the library and reading the dataset
library(arules)
library(Matrix)
groceries<- read.transactions("groceries.csv", sep=',')
summary(groceries)
```
# Part 2.3(i.) 
```{r}
basket_def_rules<- apriori(groceries,parameter = list(support = 0.1, target="rules"))
summary(basket_def_rules)
```
# By using deafult value of support we are getting zero rules

# Part 2.3(ii.) 
```{r}
basket_support<- apriori(groceries,parameter = list(support = 0.001, target="rules")) 
summary(basket_support)
```
# took the Support value = .001 for at least 400 rules. We got 410 rules

##Part 2.3 (iii)
```{r}
itemFrequencyPlot(groceries,
                  support = 0.001,
                  type="relative",
                  topN=10, # can be changed to the number of interest
                  horiz=TRUE,
                  col='steelblue3',
                  xlab='',
                  main='Item frequency, relative')
```

# most frequently bought item is = whole milk and its frequency = 2513

##Part 2.3 (iV)
```{r}
freq <- apriori(groceries, parameter =list(support=.001, target="frequent itemsets"))
inspect(tail(freq,1,decreasing = T, by="count"))
```

# least frequently bought item is = Citrus fruit and its frequency =  10

##Part 2.3 (V)
# The top 5 rules sorted by support:
```{r}
inspect(head(basket_support,by="support", n=5))
```

##Part 2.3 (Vi)
# The top 5 rules sorted by confidence:
 
```{r}
inspect(head(basket_support,by="confidence", n=5))
```

##Part 2.3 (Vii)
# The bottom 5 rules sorted by support:
```{r}
inspect(tail(basket_support,by="support", n=5))
```

##Part 2.3 (Viii)
# The bottom 5 rules sorted by confidence:
```{r}
inspect(tail(basket_support,by="confidence", n=5))
```
